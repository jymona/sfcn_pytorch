# sfcn_pytorch
- Pytorch Implementation of Superpixel Segmentation with Full Connected Network
- The version is based on the [fuy34/superpixel_fcn](https://github.com/fuy34/superpixel_fcn) for the latest gpu.

## Setup
- python 3.9
- pytorch 1.11.0
- nvidia-smi 495.29.05
- cuda version 11.5
- RTX3090(sm86)

## Use pretrained model to show the visualization result
Change the default setting in the argparse command as you need.
```
python run_demo.py
```
Put your own images inside the ```/pretrained_demo/input```, you will get the map and visualization result under the folder ```/pretrained_demo/map_csv``` and ```/pretrained_demo/spixel_viz```.

## Data preparation
Please first download the data from the [BSDS500 Dataset](http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_full.tgz), and extract it to ```<BSDS_DIR>```.

Change the default file path in the argparse command as you need.
```
dataset_dir=<BSDS_DIR> 
dump_root=<DUMP_ROOT> # the path where the preprocessed image stored
```
To generate training and validation dataset, use ```pre_process_bsd500.py```.
```
cd data_processing
python pre_process_bsd500.py
```
To generate test dataset, use ```pre_precess_bsd500_ori_sz.py```.
```
python pre_process_bsd500_ori_sz.py
```
The three files record the absolute path of the images, named as ```train.txt```, ```val.txt``` and ```test.txt```.

## Training 
Change the default file path in the argparse command as you need.
``` 
dump_root=<DUMP_ROOT> # the path where the preprocessed image stored
save_path=<CKPT_LOG>
pretrained_model=<PRETRAINED_CKPT>
writer_dir=<WRITER_RECORD> # the path where you store the SummaryWriter for the TensorBoardX
```
If you set the ```<PRETARINED_CKPT_DIR>```, you will fine-tine the pretrained model. 
```
python main.py
```

We can view the training log by using ```tensorboard.sh```.

## Test
The test code can provide two kinds of results:
(1) superpixel visualization,
(2) mapcsv file.

To test on BSDS500,

run ```python run_infer_bsds.py --dump_root=<DUMP_DIR> --save_path=<TEST_RESULT_DIR> --pretrained_model=<PATH_TO_THE_CKPT>```

To test on NYUv2, please first extract their pre-processed dataset from /nyu_test_set/nyu_preprocess_tst.tar.gz to ```<NYU_TEST>```.

Run ```python run_infer_nyu.py --data_dir=<NYU_TEST> --output=<TEST_OUTPUT_DIR> --pretrained=<PATH_TO_THE_CKPT>```

To test on other datasets, please first put the datasets into one folder ```<CUSTOM_DIR>```, and then convert them into the same format (e.g. ```.png``` or ```.jpg```) if necessary.

Run ```python run_demo.py --data_dir=<CUSTOM_DIR> --data_suffix=<IMG_SUFFIX> --output=<TEST_OUTPUT_DIR> --pretrained=<PATH_TO_THE_CKPT>```

In their code, superpixels with grid size ```16x16``` will be generated by default. To generate the superpixel with a different grid size, we simply need to resize the images into the appropriate resolution before passing them through the code. Please refer to ```run_infer_nyu.py``` for the details.
